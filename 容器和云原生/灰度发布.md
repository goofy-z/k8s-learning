#### 自我介绍

各位同事，早上好，我叫郑光辉，目前是在ATS部门的交行项目组做后端开发，我们项目组还有十几个同事在浦东的客户现场，今天我代表他们来公司分享目前我们做的交行云管系统的功能，会着重介绍几个，这次的topic在大半年前应该是有过一次分享

####集群扩容

自动加节点

Iaas  创建续集- 加入k8s 

提供装好的无力级或虚拟机  操作系统规范

我们按照装纳管需要的介质 

节点：

ansible 跑任务 装 kubelet 装 filebeat nodeexport prometheus

批量创建nas 日志路径

对接iaas方案可行

添加节点  打label 批量创建日志路径和nas 批量添加网络

ansible 优化了使用dce命令行工具 新节点需要手动加免密 和iaas对接这一步省略 

dce -》准备机器 —〉免密 -》 命令行安装介质 脚本创建 日志路径 nas 网络

用ansible服务任务下发的方式代替了dce命令行操作，从而为集群添加节点

自主定义流程

定义节点环境变量





### 交行云原生应用管理平台

线上环境74 个项目组。其中包括手机银行，JUMP-Cloud微服务治理平台等项目组，共部署了180+的应用， 其中手机银行项目组下共部署了170+的deployment，平均日访问人数达到800+  生产4套集群  测试3套集群

#### 批次管理

删除和拷贝批次会作用到deployment，关联日志路径同样

IP预留报警

未使用应用本身预留的IP

## JUMP-CLOUD

以SpringBoot和SpringCloud核心框架为基础搭建的一个微应用平台。

具体功能：

- 网管服务

  统一入口、灰度发布、流量切换、服务路由、熔断限流、安全认证

- 业务服务

  指具体的业务微应用

- 支撑服务

  注册发现、配置管理作为单独服务，负载均衡、熔断限流集成到应用代码。

### 灰度发布

灰度发布和我们的传统发布有个很大的不同就是 灰度的中间状态会持续很长一段时间，直到业务或决策团队决定完成升级或中止升级。

#### 传统灰度

服务方通过将灰度策略配置到其自身的负载均衡节点，来实现复杂的分流策略控制，满足业务要求。一半的灰度策略可以采用按流量百分比和特殊的请求头，途中其实负载均衡做了两次负载，首先更具灰度策略进行集群选择，其次再按照集群负载策略完成实际请求的代理转发。

#### 基于微服务的灰度

传统灰度要求在一个统一的负载均衡节点上来实现策略的判断，而基于微服务架构的应用是采用客户端负载均衡机制的，和传统灰度模式有比较大的差异。看图

更复杂，涉及到服务注册发现，所以服务方配置的灰度策略必须及时同步到每一个请求方的实例上，这就必须依赖微服务基础设施的实时同步或续约同步机制，也就是说当你新增了一条灰度策略，就需要把这条策略更新到每一个请求方的客户端负载均衡控制器，从而实现请求分流

#### 基于灰度的变更流程

这里的灰度状态的工作负载是由云平台临时生成的，用户可以在自定义目标版本时基于现有版本进行镜像版本、环境变量等信息的预定义，此时修改不会直接更新到当前版本上，而是生成一个新的工作负载。在灰度任务详情页，用户可以调整实例数和规则，实时观察当前情况，这个任务可以存在数天，用于满足各类需要。此时关联的微应用不允许进行其他任何的变更操作，当用户觉得灰度任务可以完结时，需要选择是否实施升级。最终灰度版本都会被销毁



服务放通过灰度策略配置到其自身的负载均衡节点，来实现

在平台上提供了便利的部署上线功能后，用户又想着能有一种平滑过度的发布方式，能够在上面做A/B testing，于是便想到在我们现有的微应用上做一个灰度发布的功能。

前面说过了JUMP-Cloud这个微应用平台，它所管理的每一个微应用实例也叫JUMP实例，对应到我们云管是一个Deployment

整个灰度任务生命周期我们共分为四步

第一步，根据现有的deployment部署模版我们创建出一个新的灰度deployment，之后是一条默认的灰度策略，它将把目标deployment的流量全部切换到新的deployment，依托微应用平台的灰度流量控制，我们将其

第二阶段，设置灰度规则，我们允许用户自定义这两个Deployment流量的分配方式，并提供它们的请求量监控和pod监控，灰度Deployment的部署修改

第三阶段，

发布，将灰度deployment的部署模版替换到目标deployment，失效灰度策略还有删除灰度deployment







